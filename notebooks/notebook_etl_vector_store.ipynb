{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a49d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clientes configurados correctamente.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "\n",
    "# 1. CREDENCIALES (LLENAR AQU√ç)\n",
    "\n",
    "OPENAI_API_KEY = \"sk-proj-AGvGFTE0nNy49w087VkfNJSMHWJzcCfRDH8bOwa0\"\n",
    "QDRANT_URL = \"https://08a32.us-east4-0.gcp.cloud.qdrant.io\"\n",
    "QDRANT_API_KEY = \"eXVCJ9.eyJhY2Nlc3MiOiJtIn0.lj72v9z_Tns\"\n",
    "\n",
    "\n",
    "# 2. CONFIGURACI√ìN T√âCNICA\n",
    "\n",
    "COLLECTION_NAME = \"prueba_tecnica\"\n",
    "MODELO_EMBEDDING = \"text-embedding-3-small\" \n",
    "DIMENSION_VECTOR = 1536 \n",
    "\n",
    "# Inicializamos los clientes\n",
    "client_openai = OpenAI(api_key=OPENAI_API_KEY)\n",
    "client_qdrant = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n",
    "\n",
    "print(\"Clientes configurados correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97695b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Analizando todos los casos...\n",
      "Total de casos en DataFrame: 329\n",
      "\n",
      "Estad√≠sticas de longitud:\n",
      "  - Promedio: 4990 caracteres\n",
      "  - M√°ximo: 35614 caracteres\n",
      "  - M√≠nimo: 937 caracteres\n",
      "\n",
      "Casos que exceden 8000 tokens (~32,000 chars): 1\n",
      "\n",
      "CASOS PROBLEM√ÅTICOS:\n",
      "\n",
      "  Fila 321:\n",
      "    - Providencia: SU.546/23\n",
      "    - Longitud: 35,614 caracteres\n",
      "    - Tokens estimados: 8904\n",
      "    - Tema: No disponible...\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# DIAGN√ìSTICO: Identificar casos problem√°ticos\n",
    "# ============================================\n",
    "\n",
    "print(\"Analizando todos los casos...\")\n",
    "print(f\"Total de casos en DataFrame: {len(df)}\\n\")\n",
    "\n",
    "# Analizar longitud de todos los textos\n",
    "df['longitud_texto'] = df['texto_vectorizar'].str.len()\n",
    "df['longitud_tokens_estimada'] = df['longitud_texto'] / 4  # Estimaci√≥n: 1 token ‚âà 4 chars\n",
    "\n",
    "# Encontrar casos problem√°ticos\n",
    "casos_problematicos = df[df['longitud_tokens_estimada'] > 8000].copy()\n",
    "\n",
    "print(f\"Estad√≠sticas de longitud:\")\n",
    "print(f\"  - Promedio: {df['longitud_texto'].mean():.0f} caracteres\")\n",
    "print(f\"  - M√°ximo: {df['longitud_texto'].max():.0f} caracteres\")\n",
    "print(f\"  - M√≠nimo: {df['longitud_texto'].min():.0f} caracteres\")\n",
    "print(f\"\\nCasos que exceden 8000 tokens (~32,000 chars): {len(casos_problematicos)}\")\n",
    "\n",
    "if len(casos_problematicos) > 0:\n",
    "    print(\"\\nCASOS PROBLEM√ÅTICOS:\")\n",
    "    for idx, row in casos_problematicos.iterrows():\n",
    "        print(f\"\\n  Fila {idx}:\")\n",
    "        print(f\"    - Providencia: {row.get('Providencia', 'N/A')}\")\n",
    "        print(f\"    - Longitud: {row['longitud_texto']:,} caracteres\")\n",
    "        print(f\"    - Tokens estimados: {row['longitud_tokens_estimada']:.0f}\")\n",
    "        print(f\"    - Tema: {row.get('Tema - subtema', 'N/A')[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89f2e9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexi√≥n con OpenAI exitosa. Dimensi√≥n del vector: 1536\n"
     ]
    }
   ],
   "source": [
    "def get_embedding(text, model=MODELO_EMBEDDING):\n",
    "    \"\"\"Genera el vector num√©rico usando la API de OpenAI\"\"\"\n",
    "    text = text.replace(\"\\n\", \" \") # Limpieza b√°sica recomendada por OpenAI\n",
    "    return client_openai.embeddings.create(input=[text], model=model).data[0].embedding\n",
    "\n",
    "# Prueba r√°pida para ver si la llave funciona\n",
    "try:\n",
    "    test_vec = get_embedding(\"Prueba de conexi√≥n\")\n",
    "    print(f\"Conexi√≥n con OpenAI exitosa. Dimensi√≥n del vector: {len(test_vec)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error conectando con OpenAI: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3142aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados: 329 registros.\n",
      "Ejemplo de texto a vectorizar:\n",
      "--------------------------------------------------\n",
      "TEMA: No disponible. HECHOS DEL CASO: La accionante, actu√≥ como representante legal de una hija que experiment√≥ acoso escolar y fue diagnosticada con depresi√≥n y ansiedad y que deriv√≥ en una ideaci√≥n suicida. La vulneraci√≥n de derechos fundamentales se atribuye al hecho de que la instituci√≥n educativa no despleg√≥ ninguna acci√≥n para contener la precitada circunstancia y para proteger a la adolescente. Igualmente, porque trazaron un Plan Individualizado de Ajustes Razonables (PIAR) que no tuvo en cuenta las condiciones y necesidades acad√©micas especiales que requer√≠a la joven, sino que se dise√±√≥ √∫nicamente con el prop√≥sito de dar cumplimiento formal a la ley y no con la intenci√≥n de garantizar los derechos fundamentales de la adolescente, lo cual condujo a que √©sta reprobara el a√±o escolar y a que no se le permitiera realizar la nivelaci√≥n correspondiente. As√≠ mismo, porque no se dio respuesta a la solicitud presentada para que se permitieran a la estudiante hacer la nivelaci√≥n de las materias que habr√≠an acarreado que reprobara el a√±o escolar. Se analiz√≥ la siguiente tem√°tica: 1¬∞. La naturaleza del acoso escolar, los desaf√≠os y las estrategias de respuesta a escenarios de acoso escolar. 2¬∞. La relaci√≥n entre acoso escolar y salud f√≠sica, mental y emocional de los ni√±os, ni√±as y adolescentes. 3¬∞. El concepto y las caracter√≠sticas del PIAR como dispositivo de inclusi√≥n educativa y, 4¬∞. Las reglas sobre el derecho de petici√≥n. Se declar√≥ la configuraci√≥n parcial del fen√≥meno de la carencia actual de objeto por da√±o consumado, en relaci√≥n con los actos de matoneo escolar ocurridos y que conllevaron a la violaci√≥n de garant√≠as constitucionales. Paralelamente, CONCEDI√ì el amparo invocado y se dictaron medidas de restablecimiento, de contenci√≥n de las barreras en la gesti√≥n interna del acoso escolar por parte del colegio y algunas otras relativas a la pol√≠tica p√∫blica de prevenci√≥n y atenci√≥n de estudiantes inmersos en escenarios de violencia escolar sistem√°tica. En relaci√≥n con este √∫ltimo aspecto, la Sala present√≥ una breve s√≠ntesis de la presente decisi√≥n dirigida a la joven representada y otra para el resto de los estudiantes de la instituci√≥n demandada.. DECISI√ìN DEL JUEZ: RESUELVE Primero. REVOCAR la orden primera de la sentencia dictada el 4 de diciembre de 2023 por el Juzgado Segundo Penal del Circuito de Azul Claro, que neg√≥ la protecci√≥n constitucional solicitada por Camila, como representante legal de su hija, Paola, en contra de la Instituci√≥n Educativa Sol y otros. En su lugar, DECLARAR la configuraci√≥n parcial del fen√≥meno de carencia actual de objeto por da√±o consumado, como consecuencia de los actos de matoneo escolar que ya ocurrieron y conllevaron la violaci√≥n de los derechos fundamentales de Paola. Adicionalmente, respecto de las dem√°s pretensiones formuladas en el escrito de demanda, CONCEDER el amparo de sus derechos fundamentales a la educaci√≥n, la igualdad y al derecho de petici√≥n, seg√∫n las consideraciones expuestas en esta providencia. Segundo. ORDENAR a la Instituci√≥n Educativa Sol, a la Secretar√≠a de Educaci√≥n Municipal de Azul Claro y al Ministerio de Educaci√≥n Nacional que, dentro del t√©rmino m√°ximo de tres meses posterior a la notificaci√≥n de la providencia, y en una fecha acad√©mica h√°bil, realicen un acto de excusas p√∫blicas, manifestaci√≥n de compromiso institucional y agradecimiento a la menor de edad, en los t√©rminos establecidos en los fundamentos jur√≠dicos 156 y siguientes de esta providencia. Tercero. ORDENAR al Instituto Colombiano de Bienestar Familiar (ICBF) y a la Defensor√≠a del Pueblo, hacer acompa√±amiento al acto de reconocimiento establecido en el ordinal anterior, en los t√©rminos previstos en los fundamentos jur√≠dicos 156 y ss., as√≠ como en el 168. Cuarto. ORDENAR a la Instituci√≥n Educativa Sol, a la Secretar√≠a de Educaci√≥n Municipal de Azul Claro, al ICBF y al Ministerio de Educaci√≥n Nacional que, en el t√©rmino de los diez (10) d√≠as siguientes a la notificaci√≥n de esta decisi√≥n, pongan en conocimiento de la parte accionante la estrategia de formaci√≥n y evaluaci√≥n diferencial de la que trata el fundamento jur√≠dico 163 y ss. de esta decisi√≥n, y las condiciones de modo, tiempo y lugar en las que proyectan efectuarla. Una vez notificada dicha estrategia, la menor de edad y su madre informar√°n, en el t√©rmino de los dos (2) d√≠as siguientes, la decisi√≥n de acogerse a la propuesta o pactar alguno de sus elementos. La estrategia tendr√° un t√©rmino m√°ximo de duraci√≥n de dos (2) meses. Quinto. ORDENAR a la Instituci√≥n Educativa Sol que, una vez la estudiante supere los objetivos de formaci√≥n de la estrategia prevista en el ordinal cuarto de esta decisi√≥n, en el t√©rmino de una semana, haga entrega del diploma de bachiller a la menor de edad. Sexto. ORDENAR al Ministerio de Educaci√≥n Nacional que, en el t√©rmino de los seis (6) meses siguientes a la notificaci√≥n de esta decisi√≥n, complemente la pol√≠tica p√∫blica de prevenci√≥n, contenci√≥n y atenci√≥n de la violencia escolar, conforme las directrices contenidas en el fundamento jur√≠dico 143. Esto con el prop√≥sito de visibilizar el fen√≥meno del acoso escolar y la respuesta institucional que suscita, como de responder efectivamente a los desaf√≠os que impone, en especial, para los estudiantes. S√©ptimo. ORDENAR a la Instituci√≥n Educativa Sol, con la intervenci√≥n de la Secretar√≠a de Educaci√≥n Municipal, y el acompa√±amiento del Ministerio de Educaci√≥n Nacional que, durante el t√©rmino de los tres (3) meses siguientes a la notificaci√≥n de esta decisi√≥n, haga una revisi√≥n del manual de convivencia, enfocada en la previsi√≥n de estrategias y de un mecanismo de seguimiento interno sobre su efectividad en el aula. Lo anterior, de conformidad con las pautas dispuestas en el fundamento jur√≠dico 128 de esta providencia. Durante ese mismo periodo las autoridades escolares del plantel educativo deber√°n ser formadas por las dem√°s entidades para el reconocimiento y gesti√≥n efectiva de las situaciones de acoso escolar. Octavo. COMPULSAR COPIAS con destino a la Secretar√≠a de Educaci√≥n Municipal de Azul Claro para que, en el marco de sus competencias, efect√∫e las averiguaciones a las que haya lugar y determine si resulta pertinente la apertura de investigaci√≥n disciplinaria contra los docentes que habr√≠an revelado informaci√≥n contenida en la historia cl√≠nica de la menor de edad. Noveno. EXHORTAR a la Fiscal√≠a General de la Naci√≥n para que, en el marco de sus competencias constitucionales y legales, una vez analizados los hechos de manera sistem√°tica, establezca si hay lugar al desarchivo y a la continuaci√≥n de la investigaci√≥n del caso. La entidad deber√° informar a esta corporaci√≥n y al juez de primera instancia, de manera continua, el avance de la investigaci√≥n. D√©cimo. ORDENAR a la Instituci√≥n Educativa Sol que, en el t√©rmino de las cuarenta y ocho (48) horas siguientes a la notificaci√≥n de esta decisi√≥n, responda la petici√≥n radicada en sus dependencias el 17 de noviembre de 2023 por la madre de la menor de edad involucrada. Und√©cimo. CONFIRMAR parcialmente la orden segunda de la sentencia dictada el 4 de diciembre de 2023 por el Juzgado Segundo Penal del Circuito de Azul Claro, que declar√≥ la falta de legitimaci√≥n por pasiva de la Secretar√≠a de Educaci√≥n Departamental de Azul. REVOCAR aquella orden segunda en todo lo dem√°s. En consecuencia, DESVINCULAR a la Secretar√≠a de Educaci√≥n Departamental de Azul del presente tr√°mite constitucional. Duod√©cimo. LIBRAR por Secretar√≠a General la comunicaci√≥n prevista en el art√≠culo 36 del Decreto 2591 de 1991.\n"
     ]
    }
   ],
   "source": [
    "# 1. Leer Excel\n",
    "try:\n",
    "    df = pd.read_excel('Datos/sentencias_pasadas.xlsx', engine='openpyxl') # Ajusta nombre si es necesario\n",
    "    df = df.fillna(\"No disponible\")\n",
    "    print(f\"Datos cargados: {len(df)} registros.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error leyendo archivo: {e}\")\n",
    "\n",
    "# 2. Crear 'Super Texto' para contexto\n",
    "# Concatenamos TEMA + SINTESIS + RESUELVE\n",
    "df['texto_vectorizar'] = (\n",
    "    \"TEMA: \" + df['Tema - subtema'].astype(str) + \". \" +\n",
    "    \"HECHOS DEL CASO: \" + df['sintesis'].astype(str) + \". \" +\n",
    "    \"DECISI√ìN DEL JUEZ: \" + df['resuelve'].astype(str)\n",
    ")\n",
    "\n",
    "print(\"Ejemplo de texto a vectorizar:\")\n",
    "print(\"-\" * 50)\n",
    "print(df['texto_vectorizar'].iloc[99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f75d745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Reiniciando colecci√≥n: prueba_tecnica_collection_cocu...\n",
      "   -> Versi√≥n anterior eliminada.\n",
      "   -> Colecci√≥n creada vac√≠a.\n",
      "\n",
      "2. Procesando documentos con CHUNKING INTELIGENTE...\n",
      "   - Max chars por chunk: 30,000\n",
      "   - Overlap: 3,000 caracteres\n",
      "\n",
      "   Procesados 50 casos ‚Üí 50 chunks creados\n",
      "   Procesados 100 casos ‚Üí 100 chunks creados\n",
      "   Procesados 150 casos ‚Üí 150 chunks creados\n",
      "   Procesados 200 casos ‚Üí 200 chunks creados\n",
      "   Procesados 250 casos ‚Üí 250 chunks creados\n",
      "   Procesados 300 casos ‚Üí 300 chunks creados\n",
      "   Fila 321 (SU.546/23): 2 chunks\n",
      "\n",
      "3. Subiendo 330 vectores a Qdrant Cloud...\n",
      "   5 batches subidos (250 vectores)\n",
      "\n",
      "======================================================================\n",
      "REPORTE FINAL DE INDEXACI√ìN\n",
      "======================================================================\n",
      "Casos procesados: 329/329\n",
      "Total vectores creados: 330\n",
      "Casos divididos en chunks: 1\n",
      "Errores: 0\n",
      "Promedio chunks/caso: 1.00\n",
      "\n",
      "======================================================================\n",
      "CASOS DIVIDIDOS (sin p√©rdida de informaci√≥n):\n",
      "======================================================================\n",
      "  ‚Ä¢ Fila 321 - SU.546/23\n",
      "    ‚îî‚îÄ 35,614 chars ‚Üí 2 chunks\n",
      "\n",
      "¬°Colecci√≥n 'prueba_tecnica_collection_cocu' completada con CERO p√©rdida de contexto!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from qdrant_client import models\n",
    "import uuid\n",
    "\n",
    "# ============================================\n",
    "# CONFIGURACI√ìN DE CHUNKING\n",
    "# ============================================\n",
    "MAX_CHARS_POR_CHUNK = 30000  # ~7,500 tokens (seguro para OpenAI)\n",
    "OVERLAP_CHARS = 3000         # 3k de overlap para mantener contexto\n",
    "\n",
    "def crear_chunks_inteligentes(texto, max_chars=MAX_CHARS_POR_CHUNK, overlap=OVERLAP_CHARS):\n",
    "    \"\"\"Divide texto largo en chunks con overlap\"\"\"\n",
    "    if len(texto) <= max_chars:\n",
    "        return [texto]\n",
    "    \n",
    "    chunks = []\n",
    "    inicio = 0\n",
    "    \n",
    "    while inicio < len(texto):\n",
    "        fin = inicio + max_chars\n",
    "        \n",
    "        # Buscar punto de corte natural (punto, salto, espacio)\n",
    "        if fin < len(texto):\n",
    "            for separador in ['. ', '\\n', ' ']:\n",
    "                posicion = texto.rfind(separador, inicio, fin)\n",
    "                if posicion > inicio + (max_chars * 0.8):\n",
    "                    fin = posicion + len(separador)\n",
    "                    break\n",
    "        \n",
    "        chunks.append(texto[inicio:fin])\n",
    "        inicio = fin - overlap\n",
    "        \n",
    "        if inicio >= len(texto):\n",
    "            break\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# PROCESAMIENTO CON CHUNKING\n",
    "# ============================================\n",
    "print(f\"1. Reiniciando colecci√≥n: {COLLECTION_NAME}...\")\n",
    "\n",
    "if client_qdrant.collection_exists(collection_name=COLLECTION_NAME):\n",
    "    client_qdrant.delete_collection(collection_name=COLLECTION_NAME)\n",
    "    print(\"   -> Versi√≥n anterior eliminada.\")\n",
    "\n",
    "client_qdrant.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=DIMENSION_VECTOR,\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")\n",
    "print(\"   -> Colecci√≥n creada vac√≠a.\\n\")\n",
    "\n",
    "print(\"2. Procesando documentos con CHUNKING INTELIGENTE...\")\n",
    "print(f\"   - Max chars por chunk: {MAX_CHARS_POR_CHUNK:,}\")\n",
    "print(f\"   - Overlap: {OVERLAP_CHARS:,} caracteres\\n\")\n",
    "\n",
    "points = []\n",
    "casos_procesados = 0\n",
    "total_chunks = 0\n",
    "casos_divididos = []\n",
    "errores = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    \n",
    "    texto_original = row['texto_vectorizar']\n",
    "    chunks = crear_chunks_inteligentes(texto_original)\n",
    "    \n",
    "    # Registrar si se dividi√≥\n",
    "    if len(chunks) > 1:\n",
    "        casos_divididos.append({\n",
    "            \"fila\": idx,\n",
    "            \"providencia\": row.get('Providencia', 'N/A'),\n",
    "            \"longitud_original\": len(texto_original),\n",
    "            \"num_chunks\": len(chunks)\n",
    "        })\n",
    "        print(f\"  Fila {idx} ({row.get('Providencia', 'N/A')}): {len(chunks)} chunks\")\n",
    "    \n",
    "    # Procesar cada chunk\n",
    "    for chunk_num, chunk_texto in enumerate(chunks, 1):\n",
    "        try:\n",
    "            # Generar embedding\n",
    "            vector = get_embedding(chunk_texto)\n",
    "            \n",
    "            # Payload con informaci√≥n del chunk\n",
    "            payload = {\n",
    "                # Datos del caso original\n",
    "                \"id_caso\": row.get('#', idx),\n",
    "                \"fila_excel\": idx,\n",
    "                \"providencia\": row.get('Providencia', 'N/A'),\n",
    "                \"fecha\": str(row.get('Fecha Sentencia', 'N/A')),\n",
    "                \"tema\": row.get('Tema - subtema', 'N/A'),\n",
    "                \n",
    "                # Metadata COMPLETA (sin truncar)\n",
    "                \"sintesis\": str(row.get('sintesis', 'N/A')),\n",
    "                \"resuelve\": str(row.get('resuelve', 'N/A')),\n",
    "                \n",
    "                # Info del chunking\n",
    "                \"es_chunk\": len(chunks) > 1,\n",
    "                \"chunk_num\": chunk_num,\n",
    "                \"total_chunks\": len(chunks),\n",
    "                \"longitud_original\": len(texto_original),\n",
    "                \"longitud_chunk\": len(chunk_texto),\n",
    "                \n",
    "                # Texto del chunk (√∫til para debugging)\n",
    "                \"texto_chunk\": chunk_texto[:500] + \"...\" if len(chunk_texto) > 500 else chunk_texto\n",
    "            }\n",
    "            \n",
    "            points.append(models.PointStruct(\n",
    "                id=str(uuid.uuid4()),\n",
    "                vector=vector,\n",
    "                payload=payload\n",
    "            ))\n",
    "            \n",
    "            total_chunks += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            errores.append({\n",
    "                \"fila\": idx,\n",
    "                \"chunk\": chunk_num,\n",
    "                \"error\": str(e)[:200]\n",
    "            })\n",
    "            print(f\"  Error fila {idx}, chunk {chunk_num}: {str(e)[:100]}\")\n",
    "            continue\n",
    "    \n",
    "    casos_procesados += 1\n",
    "    \n",
    "    # Progreso y rate limit\n",
    "    if (idx + 1) % 50 == 0:\n",
    "        print(f\"  Procesados {casos_procesados} casos ‚Üí {total_chunks} chunks creados\")\n",
    "    \n",
    "    if idx % 10 == 0:\n",
    "        time.sleep(0.2)  # Evitar rate limit\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# SUBIDA A QDRANT\n",
    "# ============================================\n",
    "print(f\"\\n3. Subiendo {len(points)} vectores a Qdrant Cloud...\")\n",
    "\n",
    "BATCH_SIZE = 50\n",
    "batches_subidos = 0\n",
    "\n",
    "for i in range(0, len(points), BATCH_SIZE):\n",
    "    batch = points[i : i + BATCH_SIZE]\n",
    "    client_qdrant.upload_points(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        points=batch\n",
    "    )\n",
    "    batches_subidos += 1\n",
    "    if batches_subidos % 5 == 0:\n",
    "        print(f\"  {batches_subidos} batches subidos ({i + len(batch)} vectores)\")\n",
    "\n",
    "# ============================================\n",
    "# REPORTE FINAL\n",
    "# ============================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"REPORTE FINAL DE INDEXACI√ìN\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Casos procesados: {casos_procesados}/{len(df)}\")\n",
    "print(f\"Total vectores creados: {total_chunks}\")\n",
    "print(f\"Casos divididos en chunks: {len(casos_divididos)}\")\n",
    "print(f\"Errores: {len(errores)}\")\n",
    "print(f\"Promedio chunks/caso: {total_chunks/casos_procesados:.2f}\")\n",
    "\n",
    "if casos_divididos:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"CASOS DIVIDIDOS (sin p√©rdida de informaci√≥n):\")\n",
    "    print(f\"{'='*70}\")\n",
    "    for caso in casos_divididos:\n",
    "        print(f\"  ‚Ä¢ Fila {caso['fila']} - {caso['providencia']}\")\n",
    "        print(f\"    ‚îî‚îÄ {caso['longitud_original']:,} chars ‚Üí {caso['num_chunks']} chunks\")\n",
    "\n",
    "if errores:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ERRORES ENCONTRADOS:\")\n",
    "    print(f\"{'='*70}\")\n",
    "    for error in errores:\n",
    "        print(f\"  ‚Ä¢ Fila {error['fila']}, Chunk {error['chunk']}: {error['error']}\")\n",
    "\n",
    "print(f\"\\n¬°Colecci√≥n '{COLLECTION_NAME}' completada con CERO p√©rdida de contexto!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a6d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funciones RAG configuradas correctamente\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# SISTEMA RAG: B√öSQUEDA + GENERACI√ìN\n",
    "# ============================================\n",
    "\n",
    "def buscar_casos_similares(consulta, top_k=10):\n",
    "    \"\"\"\n",
    "    Busca casos similares en Qdrant usando b√∫squeda sem√°ntica.\n",
    "    Deduplica autom√°ticamente si hay chunks del mismo caso.\n",
    "    \"\"\"\n",
    "    # 1. Convertir consulta en vector\n",
    "    vector_consulta = get_embedding(consulta)\n",
    "    \n",
    "    # 2. Buscar en Qdrant (buscar m√°s para compensar duplicados)\n",
    "    resultados = client_qdrant.query_points(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query=vector_consulta,\n",
    "        limit=top_k * 3,  # Buscar 3x m√°s para deduplicar\n",
    "        with_payload=True\n",
    "    ).points\n",
    "    \n",
    "    # 3. Deduplicar por id_caso (mantener el chunk m√°s relevante)\n",
    "    casos_unicos = {}\n",
    "    for hit in resultados:\n",
    "        id_caso = hit.payload.get('id_caso', hit.payload.get('fila_excel'))\n",
    "        \n",
    "        if id_caso not in casos_unicos:\n",
    "            casos_unicos[id_caso] = hit\n",
    "        elif hit.score > casos_unicos[id_caso].score:\n",
    "            # Si encontramos un chunk mejor del mismo caso, reemplazar\n",
    "            casos_unicos[id_caso] = hit\n",
    "    \n",
    "    # 4. Retornar top_k √∫nicos\n",
    "    return list(casos_unicos.values())[:top_k]\n",
    "\n",
    "\n",
    "def buscar_casos_hibridos(consulta, keywords=None, top_k=10):\n",
    "    \"\"\"\n",
    "    B√∫squeda h√≠brida: combina b√∫squeda sem√°ntica con filtrado por palabras clave.\n",
    "    √ötil para acr√≥nimos o t√©rminos t√©cnicos espec√≠ficos (ej: PIAR).\n",
    "    \n",
    "    Args:\n",
    "        consulta: Pregunta en lenguaje natural\n",
    "        keywords: Lista de palabras clave que DEBEN aparecer (ej: ['PIAR'])\n",
    "        top_k: N√∫mero de resultados a retornar\n",
    "    \n",
    "    Returns:\n",
    "        Lista de casos que coinciden con la b√∫squeda sem√°ntica Y contienen las keywords\n",
    "    \"\"\"\n",
    "    # 1. B√∫squeda sem√°ntica normal\n",
    "    vector_consulta = get_embedding(consulta)\n",
    "    \n",
    "    # 2. Si hay keywords, buscar m√°s resultados para compensar el filtrado\n",
    "    limite = top_k * 20 if keywords else top_k * 3\n",
    "    \n",
    "    resultados = client_qdrant.query_points(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        query=vector_consulta,\n",
    "        limit=limite,\n",
    "        with_payload=True\n",
    "    ).points\n",
    "    \n",
    "    # 3. Filtrar por keywords si se especificaron\n",
    "    if keywords:\n",
    "        resultados_filtrados = []\n",
    "        for hit in resultados:\n",
    "            # Buscar keywords en s√≠ntesis, resuelve o tema\n",
    "            texto_completo = (\n",
    "                str(hit.payload.get('sintesis', '')) + \" \" +\n",
    "                str(hit.payload.get('resuelve', '')) + \" \" +\n",
    "                str(hit.payload.get('tema', '')) + \" \" +\n",
    "                str(hit.payload.get('texto_chunk', ''))\n",
    "            ).upper()\n",
    "            \n",
    "            # Verificar si TODAS las keywords est√°n presentes\n",
    "            if all(kw.upper() in texto_completo for kw in keywords):\n",
    "                resultados_filtrados.append(hit)\n",
    "        \n",
    "        resultados = resultados_filtrados\n",
    "    \n",
    "    # 4. Deduplicar por id_caso (mantener el chunk m√°s relevante)\n",
    "    casos_unicos = {}\n",
    "    for hit in resultados:\n",
    "        id_caso = hit.payload.get('id_caso', hit.payload.get('fila_excel'))\n",
    "        \n",
    "        if id_caso not in casos_unicos:\n",
    "            casos_unicos[id_caso] = hit\n",
    "        elif hit.score > casos_unicos[id_caso].score:\n",
    "            casos_unicos[id_caso] = hit\n",
    "    \n",
    "    return list(casos_unicos.values())[:top_k]\n",
    "\n",
    "\n",
    "def responder_consulta_legal(pregunta, num_casos=15, verbose=True):\n",
    "    \"\"\"\n",
    "    Sistema RAG completo: Busca casos relevantes y genera respuesta en lenguaje coloquial.\n",
    "    Detecta autom√°ticamente t√©rminos t√©cnicos (PIAR, etc.) y usa b√∫squeda h√≠brida.\n",
    "    \"\"\"\n",
    "    # Detectar t√©rminos t√©cnicos que requieren b√∫squeda h√≠brida\n",
    "    terminos_tecnicos = {\n",
    "        'PIAR': ['PIAR'],\n",
    "        'acoso escolar': ['acoso', 'escolar'],\n",
    "        'redes sociales': ['redes sociales', 'red social', 'Instagram', 'Facebook', 'Twitter', 'WhatsApp']\n",
    "    }\n",
    "    \n",
    "    keywords_detectadas = []\n",
    "    pregunta_upper = pregunta.upper()\n",
    "    \n",
    "    # Detectar PIAR espec√≠ficamente\n",
    "    if 'PIAR' in pregunta_upper:\n",
    "        keywords_detectadas = ['PIAR']\n",
    "        if verbose:\n",
    "            print(f\"B√∫squeda H√çBRIDA (detectado: PIAR) para: '{pregunta}'\")\n",
    "            print(f\"  Filtrando por keyword: PIAR\")\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(f\"Buscando casos relevantes para: '{pregunta}'\")\n",
    "    \n",
    "    # 1. Buscar casos relevantes (h√≠brido si se detect√≥ keyword)\n",
    "    if keywords_detectadas:\n",
    "        casos = buscar_casos_hibridos(pregunta, keywords=keywords_detectadas, top_k=num_casos)\n",
    "    else:\n",
    "        casos = buscar_casos_similares(pregunta, top_k=num_casos)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"  {len(casos)} casos encontrados\\n\")\n",
    "    \n",
    "    # 2. Construir contexto con los casos encontrados\n",
    "    contexto = \"CASOS LEGALES RELEVANTES:\\n\\n\"\n",
    "    for i, caso in enumerate(casos, 1):\n",
    "        payload = caso.payload\n",
    "        contexto += f\"--- CASO {i} (Relevancia: {caso.score:.2%}) ---\\n\"\n",
    "        contexto += f\"Providencia: {payload.get('providencia', 'N/A')}\\n\"\n",
    "        contexto += f\"Fecha: {payload.get('fecha', 'N/A')}\\n\"\n",
    "        contexto += f\"Tema: {payload.get('tema', 'N/A')}\\n\"\n",
    "        contexto += f\"S√≠ntesis del caso: {payload.get('sintesis', 'N/A')}\\n\"\n",
    "        contexto += f\"Sentencia: {payload.get('resuelve', 'N/A')}\\n\"\n",
    "        \n",
    "        # Info adicional si es chunk\n",
    "        if payload.get('es_chunk'):\n",
    "            contexto += f\"[Documento largo - Chunk {payload.get('chunk_num')}/{payload.get('total_chunks')}]\\n\"\n",
    "        \n",
    "        contexto += \"\\n\"\n",
    "    \n",
    "    # 3. Prompt para GPT (respuesta en lenguaje coloquial)\n",
    "    prompt = f\"\"\"Eres un asesor legal especializado en explicar casos judiciales de forma clara y sencilla a personas sin conocimientos legales.\n",
    "\n",
    "Tu tarea es responder la siguiente pregunta bas√°ndote √öNICAMENTE en los casos legales proporcionados.\n",
    "\n",
    "PREGUNTA DEL CLIENTE:\n",
    "{pregunta}\n",
    "\n",
    "{contexto}\n",
    "\n",
    "INSTRUCCIONES IMPORTANTES:\n",
    "- Responde en lenguaje coloquial, como si hablaras con un amigo que NO sabe de leyes\n",
    "- Evita t√©rminos jur√≠dicos complejos (o expl√≠calos de forma muy simple)\n",
    "- Si hay varios casos, res√∫melos de forma clara y estructurada\n",
    "- Si preguntan por sentencias, explica qu√© se decidi√≥ de manera comprensible\n",
    "- Si NO encuentras informaci√≥n relevante en los casos, dilo claramente\n",
    "- S√© preciso pero comprensible\n",
    "- Usa ejemplos o analog√≠as si ayuda a la claridad\n",
    "\n",
    "RESPUESTA EN LENGUAJE COLOQUIAL:\"\"\"\n",
    "    \n",
    "    # 4. Generar respuesta con GPT\n",
    "    respuesta = client_openai.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",  # R√°pido y econ√≥mico\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Eres un asesor legal que explica casos complejos en lenguaje simple y accesible.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.3,  # Bajo para ser m√°s preciso\n",
    "        max_tokens=2000\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"respuesta\": respuesta.choices[0].message.content,\n",
    "        \"casos_usados\": casos,\n",
    "        \"num_casos\": len(casos),\n",
    "        \"relevancia_promedio\": sum(c.score for c in casos) / len(casos) if casos else 0\n",
    "    }\n",
    "\n",
    "print(\"Funciones RAG configuradas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e79888f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Verificando casos con PIAR en el dataset original...\n",
      "\n",
      " Casos con 'PIAR' encontrados: 2\n",
      "\n",
      " Detalles de los casos con PIAR:\n",
      "\n",
      "   Fila 99:\n",
      "   - Providencia: T-249/24\n",
      "   - Tema: No disponible...\n",
      "   - Contexto: ...para contener la precitada circunstancia y para proteger a la adolescente. Igualmente, porque trazaron un Plan Individualizado de Ajustes Razonables (PIAR) que no tuvo en cuenta las condiciones y necesidades acad√©micas especiales que requer√≠a la joven, sino que se dise√±√≥ √∫nicamente con el prop√≥sito ...\n",
      "\n",
      "   Fila 204:\n",
      "   - Providencia: T-085/23\n",
      "   - Tema: ACCESIBILIDAD Y ADAPTABILIDAD COMO COMPONENTES ESENCIALES DEL DERECHO A LA EDUCACION CARENCIA ACTUAL...\n",
      "   - Contexto: ...que realiz√≥ la instituci√≥n para los ni√±os y ni√±as de transici√≥n del aula regular y no se le hab√≠a realizado el Plan Individual de Ajustes Razonables (PIAR). Se resalta el hecho de que el ni√±o recuper√≥ sus habilidades de comunicaci√≥n y fue traslado a un aula regular de la instituci√≥n. Frente a la pre...\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Verificaci√≥n completada\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# VERIFICACI√ìN: Casos con PIAR en el dataset\n",
    "# ============================================\n",
    "\n",
    "print(\" Verificando casos con PIAR en el dataset original...\\n\")\n",
    "\n",
    "# Buscar en el DataFrame\n",
    "casos_piar = df[df['texto_vectorizar'].str.contains('PIAR', case=False, na=False)]\n",
    "print(f\" Casos con 'PIAR' encontrados: {len(casos_piar)}\")\n",
    "\n",
    "if len(casos_piar) > 0:\n",
    "    print(f\"\\n Detalles de los casos con PIAR:\\n\")\n",
    "    for idx, row in casos_piar.iterrows():\n",
    "        print(f\"   Fila {idx}:\")\n",
    "        print(f\"   - Providencia: {row.get('Providencia', 'N/A')}\")\n",
    "        print(f\"   - Tema: {row.get('Tema - subtema', 'N/A')[:100]}...\")\n",
    "        \n",
    "        # Buscar contexto donde aparece PIAR\n",
    "        texto = str(row['texto_vectorizar'])\n",
    "        pos_piar = texto.upper().find('PIAR')\n",
    "        if pos_piar > 0:\n",
    "            inicio = max(0, pos_piar - 150)\n",
    "            fin = min(len(texto), pos_piar + 150)\n",
    "            contexto = texto[inicio:fin]\n",
    "            print(f\"   - Contexto: ...{contexto}...\")\n",
    "        print()\n",
    "else:\n",
    "    print(\" No se encontraron casos con PIAR en el DataFrame\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Verificaci√≥n completada\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0b99da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " ASESOR LEGAL IA - RESPUESTAS A CONSULTAS\n",
      "================================================================================\n",
      "Fecha: 2026-01-28 23:45:49\n",
      "Base de datos: prueba_tecnica_collection_cocu (330 vectores, 329 casos)\n",
      "\n",
      "\n",
      "================================================================================\n",
      "PREGUNTA 1\n",
      "================================================================================\n",
      " ¬øExisten casos que hablan sobre el PIAR? Indique de qu√© trataron los casos y cu√°les fueron sus sentencias\n",
      "\n",
      " B√∫squeda H√çBRIDA (detectado: PIAR) para: '¬øExisten casos que hablan sobre el PIAR? Indique de qu√© trataron los casos y cu√°les fueron sus sentencias'\n",
      "  Filtrando por keyword: PIAR\n",
      "   2 casos encontrados\n",
      "\n",
      " RESPUESTA:\n",
      "--------------------------------------------------------------------------------\n",
      "Claro, te explico de forma sencilla lo que dicen dos casos importantes sobre el PIAR, que es el Plan Individual de Ajustes Razonables. Este plan es como un ‚Äúplan personalizado‚Äù que hacen las escuelas para ayudar a estudiantes que tienen necesidades especiales, para que puedan aprender y participar en la escuela en igualdad de condiciones.\n",
      "\n",
      "1. **Primer caso (Providencia T-085/23):**  \n",
      "Aqu√≠ se trat√≥ de un ni√±o con una discapacidad auditiva (problemas para o√≠r y hablar) que estaba en un aula especial donde usan lenguaje de se√±as. La mam√° del ni√±o dijo que su hijo fue discriminado porque no lo dejaron participar en actividades fuera de clase, como la fiesta de fin de a√±o que s√≠ hicieron para los ni√±os de las aulas normales. Adem√°s, reclam√≥ que no le hab√≠an hecho el PIAR, que es el plan para hacer los ajustes que el ni√±o necesita.  \n",
      "Lo que decidi√≥ la Corte fue que, en realidad, ya hab√≠an hecho ese plan (PIAR) y lo estaban ajustando, as√≠ que esa parte qued√≥ sin efecto porque ya se cumpli√≥. Pero s√≠ ordenaron que la escuela debe asegurarse de que los ni√±os con discapacidad auditiva puedan participar en todas las actividades culturales, sociales y deportivas, igual que los dem√°s ni√±os. Tambi√©n pidieron que hagan un evento especial para que el ni√±o no se sienta excluido. En resumen, la escuela tiene que adaptar todo para que estos ni√±os no se queden por fuera y puedan disfrutar igual.\n",
      "\n",
      "2. **Segundo caso (Providencia T-249/24):**  \n",
      "Este caso fue sobre una adolescente que sufri√≥ acoso escolar (bullying) y eso le caus√≥ problemas de salud mental como depresi√≥n y ansiedad. La mam√° dijo que la escuela hizo un PIAR, pero solo para cumplir con la ley de forma formal, sin realmente ayudar a la ni√±a con sus necesidades especiales. Por eso, la joven termin√≥ reprobando el a√±o y no le permitieron hacer la nivelaci√≥n (una especie de recuperaci√≥n para pasar de a√±o).  \n",
      "La Corte reconoci√≥ que s√≠ hubo un da√±o por el acoso y que el PIAR no fue adecuado. Por eso, ordenaron que la escuela y las autoridades hagan varias cosas: pedir disculpas p√∫blicas a la joven, mejorar la forma en que atienden el acoso escolar, revisar las reglas de la escuela para prevenir estos casos, y darle a la estudiante la oportunidad de recuperar su t√≠tulo de bachiller. Tambi√©n pidieron que las autoridades formen mejor a los profesores para que sepan c√≥mo manejar estas situaciones.\n",
      "\n",
      "**En resumen:**  \n",
      "- El PIAR es un plan que debe ser hecho con seriedad para ayudar a estudiantes con discapacidades o necesidades especiales.  \n",
      "- En el primer caso, el problema fue que el ni√±o no estaba incluido en actividades y no se hab√≠a hecho el PIAR a tiempo, pero luego se corrigi√≥. La Corte orden√≥ que se garantice la participaci√≥n plena de estos ni√±os.  \n",
      "- En el segundo caso, el PIAR fue hecho solo ‚Äúde papel‚Äù y no ayud√≥ a la estudiante que sufri√≥ bullying, por lo que la Corte orden√≥ medidas para reparar el da√±o y mejorar la atenci√≥n en la escuela.  \n",
      "\n",
      "As√≠ que s√≠, hay casos que hablan del PIAR y muestran que es fundamental que las escuelas lo hagan bien para proteger los derechos de los estudiantes con necesidades especiales o en situaciones dif√≠ciles.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Relevancia promedio: 38.29%\n",
      " Casos consultados: 2\n",
      "\n",
      " Casos m√°s relevantes:\n",
      "   1. T-085/23 - Relevancia: 40.66%\n",
      "   2. T-249/24 - Relevancia: 35.92%\n",
      "\n",
      "\n",
      "================================================================================\n",
      " TODAS LAS PREGUNTAS RESPONDIDAS\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# ============================================\n",
    "# RESPONDER PREGUNTAS DEL CASO DE NEGOCIO\n",
    "# ============================================\n",
    "\n",
    "preguntas = [\n",
    "\n",
    "    \"¬øExisten casos que hablan sobre el PIAR? Indique de qu√© trataron los casos y cu√°les fueron sus sentencias\"\n",
    "    \"¬øCu√°les son las sentencias de 3 demandas relacionadas con redes sociales?\",\n",
    "    \"¬øDe qu√© se trataron esas 3 demandas anteriores relacionadas con redes sociales?\",\n",
    "    \"¬øCu√°l fue la sentencia del caso que habla de acoso escolar?\",\n",
    "    \"¬øDiga el detalle de la demanda relacionada con acoso escolar?\",]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\" ASESOR LEGAL IA - RESPUESTAS A CONSULTAS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Base de datos: {COLLECTION_NAME} ({330} vectores, 329 casos)\\n\")\n",
    "\n",
    "resultados_finales = []\n",
    "\n",
    "for i, pregunta in enumerate(preguntas, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PREGUNTA {i}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\" {pregunta}\\n\")\n",
    "    \n",
    "    # Generar respuesta\n",
    "    resultado = responder_consulta_legal(pregunta, num_casos=15, verbose=True)\n",
    "    \n",
    "    print(f\"RESPUESTA:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(resultado[\"respuesta\"])\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"\\nRelevancia promedio: {resultado['relevancia_promedio']:.2%}\")\n",
    "    print(f\" Casos consultados: {resultado['num_casos']}\")\n",
    "    \n",
    "    # Mostrar casos usados\n",
    "    print(\"\\n Casos m√°s relevantes:\")\n",
    "    for j, caso in enumerate(resultado[\"casos_usados\"][:3], 1):\n",
    "        print(f\"   {j}. {caso.payload.get('providencia')} - Relevancia: {caso.score:.2%}\")\n",
    "    \n",
    "    # Guardar para reporte\n",
    "    resultados_finales.append({\n",
    "        \"pregunta\": pregunta,\n",
    "        \"respuesta\": resultado[\"respuesta\"],\n",
    "        \"relevancia\": f\"{resultado['relevancia_promedio']:.2%}\",\n",
    "        \"casos\": [\n",
    "            {\n",
    "                \"providencia\": c.payload.get('providencia'),\n",
    "                \"relevancia\": f\"{c.score:.2%}\",\n",
    "                \"tema\": c.payload.get('tema'),\n",
    "                \"fecha\": c.payload.get('fecha')\n",
    "            }\n",
    "            for c in resultado[\"casos_usados\"]\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Pausa para evitar rate limit\n",
    "    time.sleep(1)\n",
    "\n",
    "print(f\"\\n\\n{'='*80}\")\n",
    "print(\"TODAS LAS PREGUNTAS RESPONDIDAS\")\n",
    "print(f\"{'='*80}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
